{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "training_path = \"fruits-360_dataset/Training\"\n",
    "test_path = \"fruits-360_dataset/Test\"\n",
    "\n",
    "try:\n",
    "    STATS = np.load(\"stats.npy\", allow_pickle=True)\n",
    "except FileNotFoundError as fnf:\n",
    "    print(\"Not found stats file.\")\n",
    "    STATS = []\n",
    "\n",
    "# Parameters    \n",
    "GRAY_SCALE = False\n",
    "FRUITS = os.listdir(training_path)\n",
    "random.shuffle(FRUITS)\n",
    "\n",
    "train_load = 0.1\n",
    "test_load = 0.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_data(directory_path, load_factor=None):\n",
    "    data = []\n",
    "    labels = []\n",
    "               \n",
    "            \n",
    "    for fruit_name in FRUITS:\n",
    "        class_num = FRUITS.index(fruit_name)                \n",
    "        \n",
    "        path = os.path.join(directory_path, fruit_name)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            if load_factor and np.random.random() > load_factor:  # skip image\n",
    "                continue\n",
    "                \n",
    "            img_path = os.path.join(path, img)    \n",
    "            if GRAY_SCALE:\n",
    "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            else:\n",
    "                image = cv2.imread(img_path)\n",
    "                image = image[:, :, [2, 1, 0]]\n",
    "                \n",
    "            image = image / 255.0\n",
    "            image = np.array(image, dtype=np.single)  # Reduce precision and memory consumption\n",
    "                             \n",
    "            data.append([image, class_num])\n",
    "\n",
    "    random.shuffle(data)\n",
    "        \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    \n",
    "    for image, label in data:\n",
    "        X.append(image)\n",
    "        y.append(label)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    if GRAY_SCALE:\n",
    "        print(\"Reshaping gray scale\")\n",
    "        X = X.reshape(-1, X.shape[1], X.shape[2], 1)\n",
    "        \n",
    "    return X, y      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_training, y_training = load_data(training_path, load_factor=train_load)\n",
    "print(\"Created training array\")    \n",
    "print(f\"X shape: {X_training.shape}\")\n",
    "print(f\"y shape: {y_training.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_test, y_test = load_data(test_path, load_factor=test_load)\n",
    "\n",
    "print(\"Created test arrays\")    \n",
    "print(f\"X shape: {X_test.shape}\")\n",
    "print(f\"y shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AfterTwoEpochStop(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, acc_threshold, loss_threshold):\n",
    "#         super(AfterTwoEpochStop, self).__init__()\n",
    "        self.acc_threshold = acc_threshold\n",
    "        self.loss_threshold = loss_threshold\n",
    "        self.checked = False\n",
    "        print(\"Init\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        acc = logs[\"accuracy\"]   \n",
    "        loss = logs[\"loss\"]\n",
    "        if acc >= self.acc_threshold and loss <= self.loss_threshold:\n",
    "            if self.checked:\n",
    "                self.model.stop_training = True\n",
    "            else:\n",
    "                self.checked = True\n",
    "        else:\n",
    "            self.checked = False\n",
    "\n",
    "stop = AfterTwoEpochStop(acc_threshold=0.98, loss_threshold=0.05)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit gpu memory usage\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = False\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.compat.v1.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Conv3D, MaxPooling2D, MaxPooling3D, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dense_layers = [2]\n",
    "dense_size = [32, 64]\n",
    "conv_layers = [1, 2, 3]\n",
    "conv_size = [32, 64]\n",
    "conv_shape = [2, 5]\n",
    "\n",
    "pic_shape = X_training.shape[1:]\n",
    "label_count = len(FRUITS)\n",
    "\n",
    "\n",
    "run_num = 0\n",
    "total = len(dense_layers)*len(dense_size)*len(conv_layers)*len(conv_size)*len(conv_shape)\n",
    "for dl in dense_layers:\n",
    "    for ds in dense_size:\n",
    "        for cl in conv_layers:\n",
    "            for cs in conv_size:                \n",
    "                for csh in conv_shape: \n",
    "                    run_num += 1\n",
    "                    with tf.compat.v1.Session(config=config) as sess:\n",
    "                        \n",
    "                        NAME = f\"{cl}xConv({cs:>03})_shape{csh}-{dl}xDense({ds:>03})-{time.time():10.0f}\"\n",
    "                        \n",
    "\n",
    "                        tensorboard = TensorBoard(log_dir=f'logs-optimize/{NAME}')\n",
    "                        model = None\n",
    "                        model = tf.keras.models.Sequential()\n",
    "\n",
    "                        model.add(Conv2D(cs, (csh, csh), activation='relu', input_shape=pic_shape))\n",
    "                        model.add(MaxPooling2D())\n",
    "\n",
    "                        for i in range(cl-1):\n",
    "                            model.add(Conv2D(cs, (csh, csh), activation='relu'))\n",
    "                            model.add(MaxPooling2D())\n",
    "\n",
    "                        model.add(Flatten())\n",
    "\n",
    "                        for x in range(dl):\n",
    "                            model.add(Dense(ds, activation='relu'))\n",
    "\n",
    "                        model.add(Dense(label_count, activation='softmax'))\n",
    "\n",
    "                        model.compile(optimizer='adam',\n",
    "                                      loss='sparse_categorical_crossentropy',\n",
    "                                      metrics=['accuracy'])\n",
    "\n",
    "                        history = model.fit(X_training, y_training, \n",
    "                                            batch_size=25, epochs=10,\n",
    "                                            validation_data=(X_test, y_test),                                   \n",
    "                                            callbacks=[tensorboard, stop])\n",
    "\n",
    "                        loss = history.history['loss']\n",
    "                        accuracy = history.history['accuracy']\n",
    "\n",
    "                        val_loss = history.history['val_loss']\n",
    "                        val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "                        print(f\"{(run_num/total)*100:<5.1f}% - {NAME} Results: \")\n",
    "    #                     print(f\"Test Accuracy: {val_accuracy[-1]:>2.4f}\")\n",
    "    #                     print(f\"Test loss: {val_loss[-1]:>2.4f}\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
